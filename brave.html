<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Brave</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

<div class="works-container">
  <h1 class="works-header">Brave, 2024</h1>
    <p class="works-back">
      <a href="./home.html">(home)</a>
    </p>
</div>

  <div class="image-grid">
    <img src="./assets/images/proto.webp" alt="Brave in prototyping stage" class="img-proto"/>
    <img src="./assets/images/brave.webp" alt="Final version of Brave" class="img-brave"/>
    <img src="./assets/images/winter.webp" alt="Brave presented at the CCI winter festival" class="img-winter"/>
    <img src="./assets/images/ouroboros.svg" alt="Ouroboros" class="img-neutral"/>
  </div>

  <div id="proust-animated"></div>
  <script src="typewriter.js"></script>

  <div class = "works-text-container">
    <div class="left-text-box">
      Technologies & Links <br>
      <span class="hyphen-line"></span>
      Raspberry Pi 5 <br>
      C++ Libtorch Backend <br>
      Pure Data Sound<br>
      Circuit Python <br>
      3D-Printed Housing <br><br>
    
      <a class="link" href="https://www.youtube.com/watch?v=0HugWkdesgw" target="_blank">Video Demo</a> &lt&lt&lt <br>
      <a class="link" href="https://github.com/danielmanz17/Brave" target="_blank">ICCC'25 Paper</a> &lt&lt&lt (⌐⊙_⊙)<br>
      <a class="link" href="https://github.com/danielmanz17/Brave" target="_blank">GitHub repository</a> &lt&lt&lt <br>
      <a class="link" href="https://danielmanz17.github.io/Brave-Samples/" target="_blank">Samples</a> &lt&lt&lt <br>

      <img src="./assets/images/logo.png" alt="Brave logo" class="img-logo" />

    </div>
    <div class = "right-text-box">
      Project Statement <br> 
      <span class="hyphen-line"></span>
      Brave (Bend + RAVE) is an embedded, experimental sound box can be used to twist and subvert a neural synthesis model, moving beyond the training set. 
      The instrument uses a mod of the ircam Paris RAVE model to expose internal neural network architecture/layer weights to performer (network-bending). 
      I am using a darbouka drum training set here.
      <br><br>

      As neural audio synthesis advances, inadvertently becoming an agent of cultural construction, we face increased risk of cultural homogenisation - autophagous AI feedback cycles suppressing atypical expression. 
      Training corpora are moving from the natural to the synthetic, supporting a cycle of self-consuming generative modelling. 
      As these tools are further assimilated into society and artistic practice, active divergence [1] from their monolithic output becomes increasingly necessary.<br><br>

      Methods such as data rebalancing , augmentation and poisoning aim to address this issue. 
      This work contributes to the “network-bending” framework - the direct manipulation of neural network parameters in deep generative modelling. 
      How can the manipulation of ML network architecture become, in itself, an act of creative expression? How can an artist interface with this internal architecture in the context of live performance?<br><br>

      The instrument was displayed at the UAL Creative Computing Institute Winter Festival, Eagle Wharf Gallery (London), 2024. 
      The process, working within the PoC Media and Arts technology approach [2], was published (peer-reviewed) as part of the International Conference of Computational Creativity 2025 and presented as a poster in Campinas, Brazil.   
    </div>
  </div>

  <div class = "references-text-box">
    References <br>
    <span class="hyphen-line"></span>
    [1] Broad, T., Berns, S., Colton, S., and Grierson, M. Active divergence with generative deep learning - A survey and taxonomy. CoRR abs/2107.05599 (2021). <br>
    [2] Bryan-Kinns, N., and Reed, C. N. 2023. A guide to evaluating the experience of media and arts technology <br>
  </div>
</body>
</html>
